{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AdamW, AutoModel, AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import functools\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_s2s_generate(\n",
    "    question_doc,\n",
    "    qa_s2s_model,\n",
    "    qa_s2s_tokenizer,\n",
    "    num_answers=1,\n",
    "    num_beams=None,\n",
    "    min_len=64,\n",
    "    max_len=256,\n",
    "    do_sample=False,\n",
    "    temp=1.0,\n",
    "    top_p=None,\n",
    "    top_k=None,\n",
    "    max_input_length=512,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model_inputs = make_qa_s2s_batch([(question_doc, \"A\")], qa_s2s_tokenizer, max_input_length, device=device,)\n",
    "    n_beams = num_answers if num_beams is None else max(num_beams, num_answers)\n",
    "    generated_ids = qa_s2s_model.generate(\n",
    "        input_ids=model_inputs[\"input_ids\"],\n",
    "        attention_mask=model_inputs[\"attention_mask\"],\n",
    "        min_length=min_len,\n",
    "        max_length=max_len,\n",
    "        do_sample=do_sample,\n",
    "        early_stopping=True,\n",
    "        num_beams=1 if do_sample else n_beams,\n",
    "        temperature=temp,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        eos_token_id=qa_s2s_tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=num_answers,\n",
    "        decoder_start_token_id=qa_s2s_tokenizer.bos_token_id,\n",
    "    )\n",
    "    return [qa_s2s_tokenizer.decode(ans_ids, skip_special_tokens=True).strip() for ans_ids in generated_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qa_s2s_batch(qa_list, tokenizer, max_len=64, max_a_len=360, device=\"cuda:0\"):\n",
    "    q_ls = [q for q, a in qa_list]\n",
    "    a_ls = [a for q, a in qa_list]\n",
    "    q_toks = tokenizer.batch_encode_plus(q_ls, max_length=max_len, pad_to_max_length=True)\n",
    "    q_ids, q_mask = (\n",
    "        torch.LongTensor(q_toks[\"input_ids\"]).to(device),\n",
    "        torch.LongTensor(q_toks[\"attention_mask\"]).to(device),\n",
    "    )\n",
    "    a_toks = tokenizer.batch_encode_plus(a_ls, max_length=min(max_len, max_a_len), pad_to_max_length=True)\n",
    "    a_ids, a_mask = (\n",
    "        torch.LongTensor(a_toks[\"input_ids\"]).to(device),\n",
    "        torch.LongTensor(a_toks[\"attention_mask\"]).to(device),\n",
    "    )\n",
    "    lm_labels = a_ids[:, 1:].contiguous().clone()\n",
    "    lm_labels[a_mask[:, 1:].contiguous() == 0] = -100\n",
    "    model_inputs = {\n",
    "        \"input_ids\": q_ids,\n",
    "        \"attention_mask\": q_mask,\n",
    "        \"decoder_input_ids\": a_ids[:, :-1].contiguous(),\n",
    "        \"labels\": lm_labels,\n",
    "    }\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qa_s2s_model(model_name=\"facebook/bart-large\", from_file=None, device=\"cuda:0\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                                #   device_map = 'auto'\n",
    "                                                  ).to(device)\n",
    "    print(model)\n",
    "    if from_file is not None:\n",
    "        param_dict = torch.load(from_file)  # has model weights, optimizer, and scheduler states\n",
    "        model.load_state_dict(param_dict[\"model\"])\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qa_s2s_epoch(model, dataset, tokenizer, optimizer, scheduler, args, e=0, curriculum=False):\n",
    "    model.train()\n",
    "    # make iterator\n",
    "    if curriculum:\n",
    "        train_sampler = SequentialSampler(dataset)\n",
    "    else:\n",
    "        train_sampler = RandomSampler(dataset)\n",
    "    model_collate_fn = functools.partial(\n",
    "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=args.device\n",
    "    )\n",
    "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
    "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
    "    # accumulate loss since last print\n",
    "    loc_steps = 0\n",
    "    loc_loss = 0.0\n",
    "    st_time = time()\n",
    "    for step, batch_inputs in enumerate(epoch_iterator):\n",
    "        # print(batch_inputs)\n",
    "        batch_inputs['labels'] = batch_inputs.pop('labels')\n",
    "        pre_loss = model(**batch_inputs)[0]\n",
    "        # print(pre_loss)\n",
    "        loss = pre_loss.sum()# / pre_loss.shape[0]\n",
    "        loss.backward()\n",
    "        # optimizer\n",
    "        if step % args.backward_freq == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "        # some printing within the epoch\n",
    "        loc_loss += loss.item()\n",
    "        loc_steps += 1\n",
    "        if step % args.print_freq == 0 or step == 1:\n",
    "            print(\n",
    "                \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
    "                    e, step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
    "                )\n",
    "            )\n",
    "            loc_loss = 0\n",
    "            loc_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qa_s2s_epoch(model, dataset, tokenizer, args):\n",
    "    model.eval()\n",
    "    # make iterator\n",
    "    train_sampler = SequentialSampler(dataset)\n",
    "    model_collate_fn = functools.partial(\n",
    "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=args.device\n",
    "    )\n",
    "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
    "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
    "    # accumulate loss since last print\n",
    "    loc_steps = 0\n",
    "    loc_loss = 0.0\n",
    "    st_time = time()\n",
    "    with torch.no_grad():\n",
    "        for step, batch_inputs in enumerate(epoch_iterator):\n",
    "            batch_inputs['labels'] = batch_inputs.pop('labels')\n",
    "            pre_loss = model(**batch_inputs)[0]\n",
    "            loss = pre_loss.sum() #/ pre_loss.shape[0]\n",
    "            loc_loss += loss.item()\n",
    "            loc_steps += 1\n",
    "            if step % args.print_freq == 0:\n",
    "                print(\n",
    "                    \"{:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
    "                        step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
    "                    )\n",
    "                )\n",
    "    print(\"Total \\t L: {:.3f} \\t -- {:.3f}\".format(loc_loss / loc_steps, time() - st_time,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, s2s_train_dset, s2s_valid_dset, s2s_args):\n",
    "    s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "    s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=400,\n",
    "        num_training_steps=(s2s_args.num_epochs + 1) * math.ceil(len(s2s_train_dset) / s2s_args.batch_size),\n",
    "    )\n",
    "    for e in range(s2s_args.num_epochs):\n",
    "        train_qa_s2s_epoch(\n",
    "            qa_s2s_model,\n",
    "            s2s_train_dset,\n",
    "            qa_s2s_tokenizer,\n",
    "            s2s_optimizer,\n",
    "            s2s_scheduler,\n",
    "            s2s_args,\n",
    "            e,\n",
    "            curriculum=(e == 0),\n",
    "        )\n",
    "        m_save_dict = {\n",
    "            \"model\": qa_s2s_model.state_dict(),\n",
    "            \"optimizer\": s2s_optimizer.state_dict(),\n",
    "            \"scheduler\": s2s_scheduler.state_dict(),\n",
    "        }\n",
    "        print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "        eval_qa_s2s_epoch(qa_s2s_model, s2s_valid_dset, qa_s2s_tokenizer, s2s_args)\n",
    "        torch.save(m_save_dict, \"{}_{}.pth\".format(s2s_args.model_save_name, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELI5DatasetS2S(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_array,\n",
    "    ):\n",
    "        self.data = data_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def append(self, question_doc, answer):\n",
    "        self.data.append([question_doc, answer])\n",
    "\n",
    "    # def make_example(self, idx):\n",
    "    #     i, j = self.qa_id_list[idx]\n",
    "    #     example = self.data[i]\n",
    "    #     question = example[\"title\"] + \" \" + example[\"selftext\"]\n",
    "    #     answer = example[\"answers\"][\"text\"][j]\n",
    "    #     q_id = example[\"q_id\"]\n",
    "    #     if self.make_doc_function is not None:\n",
    "    #         self.document_cache[q_id] = self.document_cache.get(q_id, self.make_doc_function(example[\"title\"]))\n",
    "    #     document = self.document_cache[q_id]\n",
    "    #     in_st = \"question: {} context: {}\".format(\n",
    "    #         question.lower().replace(\" --t--\", \"\").strip(), document.lower().strip(),\n",
    "    #     )\n",
    "    #     out_st = answer\n",
    "    #     return (in_st, out_st)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx][0], self.data[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file to close\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "try:\n",
    "  f.close()\n",
    "except:\n",
    "  print(\"No file to close\")\n",
    "\n",
    "path = r\"D:\\Gradients\\Bản sao của ELI5-001.jsonl\"\n",
    "f = open(path, \"r\")\n",
    "\n",
    "train_data = ELI5DatasetS2S([])\n",
    "\n",
    "for id, line in enumerate(f):\n",
    "  # print(id)\n",
    "  data = json.loads(line)\n",
    "  # print(data)\n",
    "\n",
    "  question = data['question']\n",
    "  doc = '. '.join(map(str, data['ctxs']))\n",
    "  answer = '. '.join(map(str, data['answers']))\n",
    "\n",
    "  question_doc = \"question: {} context: {}\".format(question, doc)\n",
    "\n",
    "  train_data.append(question_doc, answer)\n",
    "\n",
    "f.close()\n",
    "del question, doc, answer, question_doc, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file to close\n"
     ]
    }
   ],
   "source": [
    "# Val set\n",
    "try:\n",
    "  f.close()\n",
    "except:\n",
    "  print(\"No file to close\")\n",
    "\n",
    "path = r\"D:\\Gradients\\Bản sao của ELI5_val.jsonl\"\n",
    "f = open(path, \"r\")\n",
    "\n",
    "val_data = ELI5DatasetS2S([])\n",
    "\n",
    "for id, line in enumerate(f):\n",
    "  # print(id)\n",
    "  data = json.loads(line)\n",
    "  # print(data)\n",
    "\n",
    "  question = data['question']\n",
    "  doc = '. '.join(map(str, data['ctxs']))\n",
    "  answer = '. '.join(map(str, data['answers']))\n",
    "\n",
    "  question_doc = \"question: {} context: {}\".format(question, doc)\n",
    "\n",
    "  val_data.append(question_doc, answer)\n",
    "\n",
    "f.close()\n",
    "del question, doc, answer, question_doc, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khoav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 22,020,096 || all params: 98,981,248 || trainable%: 22.246735058341557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khoav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of 136317 \t L: 7.620 \t -- 3.851\n",
      " 0     1 of 136317 \t L: 6.736 \t -- 4.075\n",
      " 0 10000 of 136317 \t L: 4.070 \t -- 2181.946\n",
      " 0 20000 of 136317 \t L: 3.741 \t -- 4253.060\n",
      " 0 30000 of 136317 \t L: 3.724 \t -- 6171.573\n",
      " 0 40000 of 136317 \t L: 3.712 \t -- 8041.130\n",
      " 0 50000 of 136317 \t L: 3.690 \t -- 9917.033\n",
      " 0 60000 of 136317 \t L: 3.670 \t -- 11798.558\n",
      " 0 70000 of 136317 \t L: 3.667 \t -- 13671.993\n",
      " 0 80000 of 136317 \t L: 3.664 \t -- 15574.457\n",
      " 0 90000 of 136317 \t L: 3.657 \t -- 17502.440\n",
      " 0 100000 of 136317 \t L: 3.658 \t -- 19425.717\n",
      " 0 110000 of 136317 \t L: 3.649 \t -- 21292.485\n",
      " 0 120000 of 136317 \t L: 3.588 \t -- 23377.978\n",
      " 0 130000 of 136317 \t L: 3.624 \t -- 25499.549\n",
      "Saving model D:\\Gradients\\seq2seq_models\n",
      "    0 of   753 \t L: 3.721 \t -- 0.515\n",
      "Total \t L: 3.489 \t -- 347.677\n",
      " 1     0 of 136317 \t L: 3.755 \t -- 0.351\n",
      " 1     1 of 136317 \t L: 3.798 \t -- 0.612\n",
      " 1 10000 of 136317 \t L: 3.632 \t -- 2176.738\n",
      " 1 20000 of 136317 \t L: 3.631 \t -- 4118.032\n",
      " 1 30000 of 136317 \t L: 3.622 \t -- 6227.247\n",
      " 1 40000 of 136317 \t L: 3.620 \t -- 8175.931\n",
      " 1 50000 of 136317 \t L: 3.615 \t -- 10214.761\n",
      " 1 60000 of 136317 \t L: 3.612 \t -- 12369.893\n",
      " 1 70000 of 136317 \t L: 3.610 \t -- 14539.991\n",
      " 1 80000 of 136317 \t L: 3.610 \t -- 16670.427\n",
      " 1 90000 of 136317 \t L: 3.616 \t -- 18818.858\n",
      " 1 100000 of 136317 \t L: 3.616 \t -- 21022.143\n",
      " 1 110000 of 136317 \t L: 3.613 \t -- 23182.654\n",
      " 1 120000 of 136317 \t L: 3.601 \t -- 25182.021\n",
      " 1 130000 of 136317 \t L: 3.602 \t -- 27139.927\n",
      "Saving model D:\\Gradients\\seq2seq_models\n",
      "    0 of   753 \t L: 3.705 \t -- 0.397\n",
      "Total \t L: 3.465 \t -- 288.601\n",
      " 2     0 of 136317 \t L: 3.892 \t -- 0.262\n",
      " 2     1 of 136317 \t L: 3.261 \t -- 0.551\n",
      " 2 10000 of 136317 \t L: 3.596 \t -- 1943.474\n",
      " 2 20000 of 136317 \t L: 3.599 \t -- 3843.151\n",
      " 2 30000 of 136317 \t L: 3.594 \t -- 5738.591\n",
      " 2 40000 of 136317 \t L: 3.594 \t -- 7617.160\n",
      " 2 50000 of 136317 \t L: 3.597 \t -- 9483.555\n",
      " 2 60000 of 136317 \t L: 3.593 \t -- 11354.392\n",
      " 2 70000 of 136317 \t L: 3.603 \t -- 13225.989\n",
      " 2 80000 of 136317 \t L: 3.588 \t -- 15098.632\n",
      " 2 90000 of 136317 \t L: 3.589 \t -- 16965.882\n",
      " 2 100000 of 136317 \t L: 3.591 \t -- 18848.301\n",
      " 2 110000 of 136317 \t L: 3.593 \t -- 20720.494\n",
      " 2 120000 of 136317 \t L: 3.588 \t -- 22588.268\n",
      " 2 130000 of 136317 \t L: 3.589 \t -- 24455.470\n",
      "Saving model D:\\Gradients\\seq2seq_models\n",
      "    0 of   753 \t L: 3.704 \t -- 0.361\n",
      "Total \t L: 3.452 \t -- 245.597\n"
     ]
    }
   ],
   "source": [
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2\n",
    "        self.backward_freq = 16\n",
    "        self.max_length = 512\n",
    "        self.print_freq = 10000\n",
    "        self.model_save_name = \"D:\\Gradients\\seq2seq_models\\flan-t5-small\"\n",
    "        self.learning_rate = 3e-4\n",
    "        self.num_epochs = 3\n",
    "        self.device = 'cuda:0'\n",
    "\n",
    "s2s_args = ArgumentsS2S()\n",
    "\n",
    "qa_s2s_tokenizer, qa_s2s_model = make_qa_s2s_model(\n",
    "    model_name=\"google/flan-t5-small\",\n",
    "    from_file=None,\n",
    "    device=s2s_args.device\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=512,\n",
    "    lora_alpha=1024,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "qa_s2s_model = get_peft_model(qa_s2s_model, peft_config)\n",
    "qa_s2s_model.print_trainable_parameters()\n",
    "\n",
    "train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, train_data, val_data, s2s_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
