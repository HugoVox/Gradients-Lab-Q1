{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AdamW, AutoModel, AutoModelForSeq2SeqLM, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import functools\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_s2s_generate(\n",
    "    question_doc,\n",
    "    qa_s2s_model,\n",
    "    qa_s2s_tokenizer,\n",
    "    num_answers=1,\n",
    "    num_beams=None,\n",
    "    min_len=64,\n",
    "    max_len=256,\n",
    "    do_sample=False,\n",
    "    temp=1.0,\n",
    "    top_p=None,\n",
    "    top_k=None,\n",
    "    max_input_length=512,\n",
    "    device=\"cuda:0\",\n",
    "):\n",
    "    model_inputs = make_qa_s2s_batch([(question_doc, \"A\")], qa_s2s_tokenizer, max_input_length, device=device,)\n",
    "    n_beams = num_answers if num_beams is None else max(num_beams, num_answers)\n",
    "    generated_ids = qa_s2s_model.generate(\n",
    "        input_ids=model_inputs[\"input_ids\"],\n",
    "        attention_mask=model_inputs[\"attention_mask\"],\n",
    "        min_length=min_len,\n",
    "        max_length=max_len,\n",
    "        do_sample=do_sample,\n",
    "        early_stopping=True,\n",
    "        num_beams=1 if do_sample else n_beams,\n",
    "        temperature=temp,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        eos_token_id=qa_s2s_tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_return_sequences=num_answers,\n",
    "        decoder_start_token_id=qa_s2s_tokenizer.bos_token_id,\n",
    "    )\n",
    "    return [qa_s2s_tokenizer.decode(ans_ids, skip_special_tokens=True).strip() for ans_ids in generated_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qa_s2s_batch(qa_list, tokenizer, max_len=64, max_a_len=360, device=\"cuda:0\"):\n",
    "    q_ls = [q for q, a in qa_list]\n",
    "    a_ls = [a for q, a in qa_list]\n",
    "    q_toks = tokenizer.batch_encode_plus(q_ls, max_length=max_len, pad_to_max_length=True)\n",
    "    q_ids, q_mask = (\n",
    "        torch.LongTensor(q_toks[\"input_ids\"]).to(device),\n",
    "        torch.LongTensor(q_toks[\"attention_mask\"]).to(device),\n",
    "    )\n",
    "    a_toks = tokenizer.batch_encode_plus(a_ls, max_length=min(max_len, max_a_len), pad_to_max_length=True)\n",
    "    a_ids, a_mask = (\n",
    "        torch.LongTensor(a_toks[\"input_ids\"]).to(device),\n",
    "        torch.LongTensor(a_toks[\"attention_mask\"]).to(device),\n",
    "    )\n",
    "    lm_labels = a_ids[:, 1:].contiguous().clone()\n",
    "    lm_labels[a_mask[:, 1:].contiguous() == 0] = -100\n",
    "    model_inputs = {\n",
    "        \"input_ids\": q_ids,\n",
    "        \"attention_mask\": q_mask,\n",
    "        \"decoder_input_ids\": a_ids[:, :-1].contiguous(),\n",
    "        \"labels\": lm_labels,\n",
    "    }\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qa_s2s_model(model_name=\"facebook/bart-large\", from_file=None, device=\"cuda:0\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name, \n",
    "                                                  device_map = 'auto'\n",
    "                                                  ).to(device)\n",
    "    print(model)\n",
    "    if from_file is not None:\n",
    "        param_dict = torch.load(from_file)  # has model weights, optimizer, and scheduler states\n",
    "        model.load_state_dict(param_dict[\"model\"])\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qa_s2s_epoch(model, dataset, tokenizer, optimizer, scheduler, args, e=0, curriculum=False):\n",
    "    model.train()\n",
    "    # make iterator\n",
    "    if curriculum:\n",
    "        train_sampler = SequentialSampler(dataset)\n",
    "    else:\n",
    "        train_sampler = RandomSampler(dataset)\n",
    "    model_collate_fn = functools.partial(\n",
    "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=args.device\n",
    "    )\n",
    "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
    "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
    "    # accumulate loss since last print\n",
    "    loc_steps = 0\n",
    "    loc_loss = 0.0\n",
    "    st_time = time()\n",
    "    for step, batch_inputs in enumerate(epoch_iterator):\n",
    "        # print(batch_inputs)\n",
    "        batch_inputs['labels'] = batch_inputs.pop('labels')\n",
    "        pre_loss = model(**batch_inputs)[0]\n",
    "        # print(pre_loss)\n",
    "        loss = pre_loss.sum()# / pre_loss.shape[0]\n",
    "        loss.backward()\n",
    "        # optimizer\n",
    "        if step % args.backward_freq == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            model.zero_grad()\n",
    "        # some printing within the epoch\n",
    "        loc_loss += loss.item()\n",
    "        loc_steps += 1\n",
    "        if step % args.print_freq == 0 or step == 1:\n",
    "            print(\n",
    "                \"{:2d} {:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
    "                    e, step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
    "                )\n",
    "            )\n",
    "            loc_loss = 0\n",
    "            loc_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qa_s2s_epoch(model, dataset, tokenizer, args):\n",
    "    model.eval()\n",
    "    # make iterator\n",
    "    train_sampler = SequentialSampler(dataset)\n",
    "    model_collate_fn = functools.partial(\n",
    "        make_qa_s2s_batch, tokenizer=tokenizer, max_len=args.max_length, device=args.device\n",
    "    )\n",
    "    data_loader = DataLoader(dataset, batch_size=args.batch_size, sampler=train_sampler, collate_fn=model_collate_fn)\n",
    "    epoch_iterator = tqdm(data_loader, desc=\"Iteration\", disable=True)\n",
    "    # accumulate loss since last print\n",
    "    loc_steps = 0\n",
    "    loc_loss = 0.0\n",
    "    st_time = time()\n",
    "    with torch.no_grad():\n",
    "        for step, batch_inputs in enumerate(epoch_iterator):\n",
    "            batch_inputs['labels'] = batch_inputs.pop('labels')\n",
    "            pre_loss = model(**batch_inputs)[0]\n",
    "            loss = pre_loss.sum() #/ pre_loss.shape[0]\n",
    "            loc_loss += loss.item()\n",
    "            loc_steps += 1\n",
    "            if step % args.print_freq == 0:\n",
    "                print(\n",
    "                    \"{:5d} of {:5d} \\t L: {:.3f} \\t -- {:.3f}\".format(\n",
    "                        step, len(dataset) // args.batch_size, loc_loss / loc_steps, time() - st_time,\n",
    "                    )\n",
    "                )\n",
    "    print(\"Total \\t L: {:.3f} \\t -- {:.3f}\".format(loc_loss / loc_steps, time() - st_time,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, s2s_train_dset, s2s_valid_dset, s2s_args):\n",
    "    s2s_optimizer = AdamW(qa_s2s_model.parameters(), lr=s2s_args.learning_rate, eps=1e-8)\n",
    "    s2s_scheduler = get_linear_schedule_with_warmup(\n",
    "        s2s_optimizer,\n",
    "        num_warmup_steps=400,\n",
    "        num_training_steps=(s2s_args.num_epochs + 1) * math.ceil(len(s2s_train_dset) / s2s_args.batch_size),\n",
    "    )\n",
    "    for e in range(s2s_args.num_epochs):\n",
    "        train_qa_s2s_epoch(\n",
    "            qa_s2s_model,\n",
    "            s2s_train_dset,\n",
    "            qa_s2s_tokenizer,\n",
    "            s2s_optimizer,\n",
    "            s2s_scheduler,\n",
    "            s2s_args,\n",
    "            e,\n",
    "            curriculum=(e == 0),\n",
    "        )\n",
    "        m_save_dict = {\n",
    "            \"model\": qa_s2s_model.state_dict(),\n",
    "            \"optimizer\": s2s_optimizer.state_dict(),\n",
    "            \"scheduler\": s2s_scheduler.state_dict(),\n",
    "        }\n",
    "        print(\"Saving model {}\".format(s2s_args.model_save_name))\n",
    "        eval_qa_s2s_epoch(qa_s2s_model, s2s_valid_dset, qa_s2s_tokenizer, s2s_args)\n",
    "        torch.save(m_save_dict, \"{}_{}.pth\".format(s2s_args.model_save_name, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELI5DatasetS2S(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_array,\n",
    "    ):\n",
    "        self.data = data_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def append(self, question_doc, answer):\n",
    "        self.data.append([question_doc, answer])\n",
    "\n",
    "    # def make_example(self, idx):\n",
    "    #     i, j = self.qa_id_list[idx]\n",
    "    #     example = self.data[i]\n",
    "    #     question = example[\"title\"] + \" \" + example[\"selftext\"]\n",
    "    #     answer = example[\"answers\"][\"text\"][j]\n",
    "    #     q_id = example[\"q_id\"]\n",
    "    #     if self.make_doc_function is not None:\n",
    "    #         self.document_cache[q_id] = self.document_cache.get(q_id, self.make_doc_function(example[\"title\"]))\n",
    "    #     document = self.document_cache[q_id]\n",
    "    #     in_st = \"question: {} context: {}\".format(\n",
    "    #         question.lower().replace(\" --t--\", \"\").strip(), document.lower().strip(),\n",
    "    #     )\n",
    "    #     out_st = answer\n",
    "    #     return (in_st, out_st)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx][0], self.data[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file to close\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "try:\n",
    "  f.close()\n",
    "except:\n",
    "  print(\"No file to close\")\n",
    "\n",
    "path = \"Bản sao của ELI5-001.jsonl\"\n",
    "f = open(path, \"r\")\n",
    "\n",
    "train_data = ELI5DatasetS2S([])\n",
    "\n",
    "for id, line in enumerate(f):\n",
    "  # print(id)\n",
    "  data = json.loads(line)\n",
    "  # print(data)\n",
    "\n",
    "  question = data['question']\n",
    "  doc = '. '.join(map(str, data['ctxs']))\n",
    "  answer = '. '.join(map(str, data['answers']))\n",
    "\n",
    "  question_doc = \"question: {} context: {}\".format(question, doc)\n",
    "\n",
    "  train_data.append(question_doc, answer)\n",
    "\n",
    "f.close()\n",
    "del question, doc, answer, question_doc, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file to close\n"
     ]
    }
   ],
   "source": [
    "# Val set\n",
    "try:\n",
    "  f.close()\n",
    "except:\n",
    "  print(\"No file to close\")\n",
    "\n",
    "path = \"Bản sao của ELI5_val.jsonl\"\n",
    "f = open(path, \"r\")\n",
    "\n",
    "val_data = ELI5DatasetS2S([])\n",
    "\n",
    "for id, line in enumerate(f):\n",
    "  # print(id)\n",
    "  data = json.loads(line)\n",
    "  # print(data)\n",
    "\n",
    "  question = data['question']\n",
    "  doc = '. '.join(map(str, data['ctxs']))\n",
    "  answer = '. '.join(map(str, data['answers']))\n",
    "\n",
    "  question_doc = \"question: {} context: {}\".format(question, doc)\n",
    "\n",
    "  val_data.append(question_doc, answer)\n",
    "\n",
    "f.close()\n",
    "del question, doc, answer, question_doc, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T5ForConditionalGeneration(\n",
      "  (shared): Embedding(32128, 512)\n",
      "  (encoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): T5Stack(\n",
      "    (embed_tokens): Embedding(32128, 512)\n",
      "    (block): ModuleList(\n",
      "      (0): T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "              (relative_attention_bias): Embedding(32, 6)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-7): 7 x T5Block(\n",
      "        (layer): ModuleList(\n",
      "          (0): T5LayerSelfAttention(\n",
      "            (SelfAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (1): T5LayerCrossAttention(\n",
      "            (EncDecAttention): T5Attention(\n",
      "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
      "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (2): T5LayerFF(\n",
      "            (DenseReluDense): T5DenseGatedActDense(\n",
      "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
      "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (act): NewGELUActivation()\n",
      "            )\n",
      "            (layer_norm): T5LayerNorm()\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (final_layer_norm): T5LayerNorm()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
      ")\n",
      "trainable params: 172,032 || all params: 77,133,184 || trainable%: 0.22303241105669902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khoav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\khoav\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0     0 of 136317 \t L: 9.022 \t -- 2.791\n",
      " 0     1 of 136317 \t L: 6.060 \t -- 3.017\n",
      " 0   100 of 136317 \t L: 7.060 \t -- 26.085\n",
      " 0   200 of 136317 \t L: 7.199 \t -- 53.934\n",
      " 0   300 of 136317 \t L: 6.997 \t -- 80.729\n",
      " 0   400 of 136317 \t L: 7.050 \t -- 109.480\n",
      " 0   500 of 136317 \t L: 6.950 \t -- 136.372\n",
      " 0   600 of 136317 \t L: 6.944 \t -- 161.829\n",
      " 0   700 of 136317 \t L: 6.811 \t -- 188.210\n",
      " 0   800 of 136317 \t L: 6.710 \t -- 215.266\n",
      " 0   900 of 136317 \t L: 6.996 \t -- 240.762\n",
      " 0  1000 of 136317 \t L: 6.744 \t -- 267.345\n",
      " 0  1100 of 136317 \t L: 6.554 \t -- 294.244\n",
      " 0  1200 of 136317 \t L: 6.514 \t -- 321.672\n",
      " 0  1300 of 136317 \t L: 6.406 \t -- 348.211\n",
      " 0  1400 of 136317 \t L: 5.995 \t -- 374.185\n",
      " 0  1500 of 136317 \t L: 5.816 \t -- 400.251\n",
      " 0  1600 of 136317 \t L: 5.756 \t -- 427.513\n",
      " 0  1700 of 136317 \t L: 5.323 \t -- 453.075\n",
      " 0  1800 of 136317 \t L: 5.221 \t -- 479.488\n",
      " 0  1900 of 136317 \t L: 4.984 \t -- 506.428\n",
      " 0  2000 of 136317 \t L: 5.056 \t -- 539.029\n",
      " 0  2100 of 136317 \t L: 4.852 \t -- 564.433\n",
      " 0  2200 of 136317 \t L: 4.879 \t -- 588.316\n",
      " 0  2300 of 136317 \t L: 4.721 \t -- 611.579\n",
      " 0  2400 of 136317 \t L: 4.698 \t -- 634.416\n",
      " 0  2500 of 136317 \t L: 4.702 \t -- 657.280\n",
      " 0  2600 of 136317 \t L: 4.685 \t -- 680.187\n",
      " 0  2700 of 136317 \t L: 4.650 \t -- 703.864\n",
      " 0  2800 of 136317 \t L: 4.599 \t -- 728.288\n",
      " 0  2900 of 136317 \t L: 4.605 \t -- 751.313\n",
      " 0  3000 of 136317 \t L: 4.585 \t -- 774.303\n",
      " 0  3100 of 136317 \t L: 4.538 \t -- 797.244\n",
      " 0  3200 of 136317 \t L: 4.506 \t -- 819.952\n",
      " 0  3300 of 136317 \t L: 4.501 \t -- 844.617\n",
      " 0  3400 of 136317 \t L: 4.513 \t -- 870.206\n",
      " 0  3500 of 136317 \t L: 4.455 \t -- 895.481\n",
      " 0  3600 of 136317 \t L: 4.465 \t -- 921.725\n",
      " 0  3700 of 136317 \t L: 4.373 \t -- 946.729\n",
      " 0  3800 of 136317 \t L: 4.401 \t -- 972.803\n",
      " 0  3900 of 136317 \t L: 4.431 \t -- 998.995\n",
      " 0  4000 of 136317 \t L: 4.382 \t -- 1027.758\n",
      " 0  4100 of 136317 \t L: 4.355 \t -- 1056.394\n",
      " 0  4200 of 136317 \t L: 4.381 \t -- 1084.779\n",
      " 0  4300 of 136317 \t L: 4.416 \t -- 1111.659\n",
      " 0  4400 of 136317 \t L: 4.361 \t -- 1139.688\n",
      " 0  4500 of 136317 \t L: 4.334 \t -- 1166.577\n",
      " 0  4600 of 136317 \t L: 4.346 \t -- 1194.770\n",
      " 0  4700 of 136317 \t L: 4.264 \t -- 1221.486\n",
      " 0  4800 of 136317 \t L: 4.320 \t -- 1248.976\n",
      " 0  4900 of 136317 \t L: 4.314 \t -- 1283.237\n",
      " 0  5000 of 136317 \t L: 4.259 \t -- 1309.447\n",
      " 0  5100 of 136317 \t L: 4.351 \t -- 1337.043\n",
      " 0  5200 of 136317 \t L: 4.302 \t -- 1365.046\n",
      " 0  5300 of 136317 \t L: 4.317 \t -- 1390.194\n",
      " 0  5400 of 136317 \t L: 4.279 \t -- 1414.393\n",
      " 0  5500 of 136317 \t L: 4.246 \t -- 1438.795\n",
      " 0  5600 of 136317 \t L: 4.218 \t -- 1463.092\n",
      " 0  5700 of 136317 \t L: 4.219 \t -- 1487.431\n",
      " 0  5800 of 136317 \t L: 4.191 \t -- 1512.039\n",
      " 0  5900 of 136317 \t L: 4.195 \t -- 1537.650\n",
      " 0  6000 of 136317 \t L: 4.210 \t -- 1562.566\n",
      " 0  6100 of 136317 \t L: 4.197 \t -- 1588.491\n",
      " 0  6200 of 136317 \t L: 4.199 \t -- 1613.235\n",
      " 0  6300 of 136317 \t L: 4.160 \t -- 1638.053\n",
      " 0  6400 of 136317 \t L: 4.164 \t -- 1663.221\n",
      " 0  6500 of 136317 \t L: 4.126 \t -- 1688.357\n",
      " 0  6600 of 136317 \t L: 4.143 \t -- 1713.859\n",
      " 0  6700 of 136317 \t L: 4.228 \t -- 1740.611\n",
      " 0  6800 of 136317 \t L: 4.149 \t -- 1773.363\n",
      " 0  6900 of 136317 \t L: 4.113 \t -- 1801.298\n",
      " 0  7000 of 136317 \t L: 4.109 \t -- 1826.840\n",
      " 0  7100 of 136317 \t L: 4.131 \t -- 1852.450\n",
      " 0  7200 of 136317 \t L: 4.150 \t -- 1877.572\n",
      " 0  7300 of 136317 \t L: 4.075 \t -- 1904.870\n",
      " 0  7400 of 136317 \t L: 4.127 \t -- 1932.387\n",
      " 0  7500 of 136317 \t L: 4.103 \t -- 1957.567\n",
      " 0  7600 of 136317 \t L: 4.083 \t -- 1982.974\n",
      " 0  7700 of 136317 \t L: 4.073 \t -- 2010.637\n",
      " 0  7800 of 136317 \t L: 4.145 \t -- 2039.301\n",
      " 0  7900 of 136317 \t L: 4.091 \t -- 2067.235\n",
      " 0  8000 of 136317 \t L: 4.111 \t -- 2091.700\n",
      " 0  8100 of 136317 \t L: 4.104 \t -- 2116.400\n",
      " 0  8200 of 136317 \t L: 4.051 \t -- 2140.794\n",
      " 0  8300 of 136317 \t L: 4.068 \t -- 2165.589\n",
      " 0  8400 of 136317 \t L: 4.048 \t -- 2190.701\n",
      " 0  8500 of 136317 \t L: 4.068 \t -- 2216.508\n",
      " 0  8600 of 136317 \t L: 4.077 \t -- 2242.055\n",
      " 0  8700 of 136317 \t L: 4.037 \t -- 2271.382\n",
      " 0  8800 of 136317 \t L: 4.057 \t -- 2296.611\n",
      " 0  8900 of 136317 \t L: 4.078 \t -- 2321.976\n",
      " 0  9000 of 136317 \t L: 4.082 \t -- 2347.074\n",
      " 0  9100 of 136317 \t L: 3.999 \t -- 2371.596\n",
      " 0  9200 of 136317 \t L: 4.046 \t -- 2397.480\n",
      " 0  9300 of 136317 \t L: 4.052 \t -- 2423.696\n",
      " 0  9400 of 136317 \t L: 4.041 \t -- 2451.369\n",
      " 0  9500 of 136317 \t L: 4.047 \t -- 2477.158\n",
      " 0  9600 of 136317 \t L: 4.049 \t -- 2502.086\n",
      " 0  9700 of 136317 \t L: 4.042 \t -- 2526.466\n",
      " 0  9800 of 136317 \t L: 4.018 \t -- 2551.513\n",
      " 0  9900 of 136317 \t L: 4.010 \t -- 2579.422\n",
      " 0 10000 of 136317 \t L: 4.024 \t -- 2607.249\n",
      " 0 10100 of 136317 \t L: 3.980 \t -- 2634.739\n",
      " 0 10200 of 136317 \t L: 4.014 \t -- 2660.961\n",
      " 0 10300 of 136317 \t L: 4.037 \t -- 2685.631\n",
      " 0 10400 of 136317 \t L: 4.037 \t -- 2710.689\n",
      " 0 10500 of 136317 \t L: 4.019 \t -- 2736.533\n",
      " 0 10600 of 136317 \t L: 4.040 \t -- 2762.051\n",
      " 0 10700 of 136317 \t L: 3.993 \t -- 2786.329\n",
      " 0 10800 of 136317 \t L: 4.101 \t -- 2811.318\n",
      " 0 10900 of 136317 \t L: 4.007 \t -- 2836.354\n",
      " 0 11000 of 136317 \t L: 3.964 \t -- 2861.255\n",
      " 0 11100 of 136317 \t L: 4.004 \t -- 2884.939\n",
      " 0 11200 of 136317 \t L: 3.994 \t -- 2908.057\n",
      " 0 11300 of 136317 \t L: 4.017 \t -- 2931.638\n",
      " 0 11400 of 136317 \t L: 4.016 \t -- 2956.074\n",
      " 0 11500 of 136317 \t L: 4.002 \t -- 2979.174\n",
      " 0 11600 of 136317 \t L: 4.043 \t -- 3003.048\n",
      " 0 11700 of 136317 \t L: 3.976 \t -- 3026.065\n",
      " 0 11800 of 136317 \t L: 4.023 \t -- 3049.151\n",
      " 0 11900 of 136317 \t L: 3.974 \t -- 3072.435\n",
      " 0 12000 of 136317 \t L: 4.007 \t -- 3095.933\n",
      " 0 12100 of 136317 \t L: 4.000 \t -- 3119.405\n",
      " 0 12200 of 136317 \t L: 3.994 \t -- 3142.697\n",
      " 0 12300 of 136317 \t L: 3.982 \t -- 3167.049\n",
      " 0 12400 of 136317 \t L: 3.985 \t -- 3190.434\n",
      " 0 12500 of 136317 \t L: 4.016 \t -- 3213.529\n",
      " 0 12600 of 136317 \t L: 4.006 \t -- 3237.671\n",
      " 0 12700 of 136317 \t L: 4.022 \t -- 3262.135\n",
      " 0 12800 of 136317 \t L: 3.978 \t -- 3286.483\n",
      " 0 12900 of 136317 \t L: 3.980 \t -- 3309.880\n",
      " 0 13000 of 136317 \t L: 3.983 \t -- 3333.484\n",
      " 0 13100 of 136317 \t L: 3.986 \t -- 3357.056\n",
      " 0 13200 of 136317 \t L: 3.927 \t -- 3380.381\n",
      " 0 13300 of 136317 \t L: 4.032 \t -- 3403.572\n",
      " 0 13400 of 136317 \t L: 3.984 \t -- 3426.844\n",
      " 0 13500 of 136317 \t L: 4.002 \t -- 3450.420\n",
      " 0 13600 of 136317 \t L: 3.981 \t -- 3473.585\n",
      " 0 13700 of 136317 \t L: 3.991 \t -- 3497.315\n",
      " 0 13800 of 136317 \t L: 3.987 \t -- 3521.764\n",
      " 0 13900 of 136317 \t L: 3.947 \t -- 3545.235\n",
      " 0 14000 of 136317 \t L: 3.926 \t -- 3569.337\n",
      " 0 14100 of 136317 \t L: 3.946 \t -- 3594.109\n",
      " 0 14200 of 136317 \t L: 3.938 \t -- 3617.947\n"
     ]
    }
   ],
   "source": [
    "class ArgumentsS2S():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 2\n",
    "        self.backward_freq = 16\n",
    "        self.max_length = 1024\n",
    "        self.print_freq = 100\n",
    "        self.model_save_name = \"seq2seq_models/eli5_flan_t5_model\"\n",
    "        self.learning_rate = 3e-4\n",
    "        self.num_epochs = 3\n",
    "        self.device = 'cuda:0'\n",
    "\n",
    "s2s_args = ArgumentsS2S()\n",
    "\n",
    "qa_s2s_tokenizer, qa_s2s_model = make_qa_s2s_model(\n",
    "    model_name=\"google/flan-t5-small\",\n",
    "    from_file=None,\n",
    "    device=s2s_args.device\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.02,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "qa_s2s_model = get_peft_model(qa_s2s_model, peft_config)\n",
    "qa_s2s_model.print_trainable_parameters()\n",
    "\n",
    "train_qa_s2s(qa_s2s_model, qa_s2s_tokenizer, train_data, val_data, s2s_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
